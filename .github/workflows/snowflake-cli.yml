name: Snowflake Model Auto-Sync to GitHub

on:
  # üü¢ Triggered remotely via REST API (e.g., Willow Activate, Snowflake, Jenkins)
  repository_dispatch:
    types: [model_sync]

  # üîµ Triggered automatically on any code push or merge to main
  push:
    branches:
      - main

permissions:
  contents: write

jobs:
  sync-snowflake-model:
    runs-on: ubuntu-latest
    name: Fetch and Commit Latest Model from Snowflake

    steps:
      # 1Ô∏è‚É£ Checkout repository
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # required for rebase

      # 2Ô∏è‚É£ Install dependencies
      - name: Install Snowflake CLI and jq
        run: |
          echo "üß∞ Installing Snowflake CLI and jq..."
          pip install --upgrade snowflake-cli-labs
          sudo apt-get install -y jq
          snow --version

      # 3Ô∏è‚É£ Configure Snowflake credentials
      - name: Configure Snowflake connection
        env:
          SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
          SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}
          SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
          SNOWFLAKE_ROLE: ${{ secrets.SNOWFLAKE_ROLE }}
          SNOWFLAKE_WAREHOUSE: ${{ secrets.SNOWFLAKE_WAREHOUSE }}
          SNOWFLAKE_DATABASE: ${{ github.event.client_payload.database || secrets.SNOWFLAKE_DATABASE }}
          SNOWFLAKE_SCHEMA: ${{ github.event.client_payload.schema || secrets.SNOWFLAKE_SCHEMA }}
        run: |
          mkdir -p ~/.snowflake
          cat <<EOF > ~/.snowflake/config.toml
          [connections.default]
          account = "${SNOWFLAKE_ACCOUNT}"
          user = "${SNOWFLAKE_USER}"
          password = "${SNOWFLAKE_PASSWORD}"
          role = "${SNOWFLAKE_ROLE}"
          warehouse = "${SNOWFLAKE_WAREHOUSE}"
          database = "${SNOWFLAKE_DATABASE}"
          schema = "${SNOWFLAKE_SCHEMA}"
          EOF
          chmod 600 ~/.snowflake/config.toml
          echo "‚úÖ Snowflake connection configured successfully."

      # 4Ô∏è‚É£ Trigger Snowflake ML pipeline
      - name: Trigger Snowflake ML pipeline
        run: |
          echo "üöÄ Executing Snowflake ML pipeline..."
          snow sql -q "
            USE WAREHOUSE MLOPS_WH;
            USE DATABASE ${{ github.event.client_payload.database || 'POWERCONSUMPTION' }};
            USE SCHEMA ${{ github.event.client_payload.schema || 'PUBLIC' }};
            EXECUTE TASK TASK_1_DATA_INGESTION;
          "
          echo "‚úÖ Pipeline triggered successfully."

      # 5Ô∏è‚É£ Wait for training success
      - name: Wait for TASK_3_MODEL_TRAINING success
        shell: bash
        run: |
          echo "‚è≥ Waiting for TASK_3_MODEL_TRAINING success..."
          ATTEMPTS=20
          SLEEP_SEC=30
          i=1
          while [ $i -le $ATTEMPTS ]; do
            count=$(snow sql --format csv -q "SELECT COUNT(*) FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY(SCHEDULED_TIME_RANGE_START => DATEADD('minute', -60, CURRENT_TIMESTAMP()))) WHERE NAME = 'TASK_3_MODEL_TRAINING' AND STATE = 'SUCCEEDED';" | tail -n +2 | cut -d',' -f1)
            echo "üîé success_count(last 60m) = ${count}"
            if [ "${count}" != "0" ]; then
              echo "‚úÖ Training task succeeded recently."
              break
            fi
            i=$((i+1))
            echo "‚Ä¶not done yet, sleeping ${SLEEP_SEC}s"
            sleep ${SLEEP_SEC}
          done
          if [ "${count}" = "0" ]; then
            echo "‚ùå Training task did not report success in time."
            exit 1
          fi

      # 6Ô∏è‚É£ List and fetch ONNX model
      - name: Download latest ONNX model and push to repo
        run: |
          echo "üì• Fetching latest ONNX file..."
          mkdir -p staged_models
          json_out=$(snow sql -q "
            USE DATABASE ${{ github.event.client_payload.database || 'POWERCONSUMPTION' }};
            USE SCHEMA ${{ github.event.client_payload.schema || 'PUBLIC' }};
            LIST @${{ github.event.client_payload.stage || 'ML_MODELS_STAGE' }} PATTERN='${{ github.event.client_payload.model_pattern || ".*\\.onnx" }}';
          " --format json)

          latest_file=$(echo "$json_out" | jq -r '
            flatten
            | map(select(.name? != null))
            | sort_by(
                ( .last_modified
                  | sub(", "; " ")
                  | strptime("%a %d %b %Y %H:%M:%S GMT")
                  | mktime )
              )
            | reverse
            | .[0].name
          ')
          if [ -z "$latest_file" ] || [ "$latest_file" == "null" ]; then
            echo "‚ùå No ONNX files found!"
            exit 1
          fi
          clean_file=${latest_file#ml_models_stage/}
          echo "‚úÖ Latest model file: $clean_file"
          snow sql -q "GET @${{ github.event.client_payload.stage || 'ML_MODELS_STAGE' }}/$clean_file file://staged_models/"
          echo "‚úÖ Model downloaded successfully!"

          git config user.name "github-actions"
          git config user.email "actions@github.com"
          git add staged_models/
          git commit -m "Auto-sync ONNX model from Snowflake stage ($clean_file)" || echo "No new model changes"
          git pull --rebase origin main || true
          git push origin main
          echo "‚úÖ Model pushed successfully!"

      # 7Ô∏è‚É£ Summary
      - name: Summary
        run: |
          echo "‚úÖ Workflow executed successfully!"
          echo "‚úÖ Latest ONNX model synced to GitHub under staged_models/ directory."
