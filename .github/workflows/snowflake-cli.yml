name: Snowflake End-to-End Model Pipeline (Stage Export, Robust)

on:
  workflow_dispatch:

jobs:
  run-snowflake-cli:
    runs-on: ubuntu-latest
    name: Trigger Tasks ‚Üí Wait for Training ‚Üí Fetch Latest ONNX ‚Üí Upload

    steps:
      # 1) Checkout
      - name: Checkout repository
        uses: actions/checkout@v4

      # 2) Install Snowflake CLI (stable)
      - name: Install Snowflake CLI
        run: |
          echo "üß∞ Installing Snowflake CLI..."
          pip install --upgrade snowflake-cli-labs
          snow --version

      # 3) Configure Snowflake credentials
      - name: Configure Snowflake credentials
        env:
          SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
          SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}
          SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
          SNOWFLAKE_ROLE: ${{ secrets.SNOWFLAKE_ROLE }}
          SNOWFLAKE_WAREHOUSE: ${{ secrets.SNOWFLAKE_WAREHOUSE }}
          SNOWFLAKE_DATABASE: ${{ secrets.SNOWFLAKE_DATABASE }}
          SNOWFLAKE_SCHEMA: ${{ secrets.SNOWFLAKE_SCHEMA }}
        run: |
          mkdir -p ~/.snowflake
          cat <<EOF > ~/.snowflake/config.toml
          [connections.default]
          account = "${SNOWFLAKE_ACCOUNT}"
          user = "${SNOWFLAKE_USER}"
          password = "${SNOWFLAKE_PASSWORD}"
          role = "${SNOWFLAKE_ROLE}"
          warehouse = "${SNOWFLAKE_WAREHOUSE}"
          database = "${SNOWFLAKE_DATABASE}"
          schema = "${SNOWFLAKE_SCHEMA}"
          EOF
          chmod 600 ~/.snowflake/config.toml
          echo "‚úÖ Snowflake credentials configured."

      # 4) Trigger the ROOT task so the whole chain runs (1->2->3->4)
      - name: Trigger Snowflake ML pipeline (root task)
        run: |
          echo "üöÄ Executing pipeline (root task) ..."
          snow sql -q "USE WAREHOUSE MLOPS_WH; USE DATABASE POWERCONSUMPTION; USE SCHEMA PUBLIC; EXECUTE TASK TASK_1_DATA_INGESTION;"
          echo "‚úÖ Root task executed."

      # 5) Poll until TASK_3_MODEL_TRAINING succeeded recently (last 45 minutes)
      - name: Wait for TASK_3_MODEL_TRAINING to succeed
        run: |
          echo "‚è≥ Polling for TASK_3_MODEL_TRAINING success (up to ~10 minutes)..."
          ATTEMPTS=20
          SLEEP_SEC=30
          i=1
          while [ $i -le $ATTEMPTS ]; do
            count=$(snow sql -q "
              SELECT COUNT(*) AS c
              FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY(
                SCHEDULED_TIME_RANGE_START => DATEADD('minute', -45, CURRENT_TIMESTAMP())
              ))
              WHERE name = 'TASK_3_MODEL_TRAINING'
                AND state = 'SUCCEEDED'
            " --format tsv | tail -n +2 | tr -d '[:space:]')
            echo "üîé success_count(last 45m) = ${count}"
            if [ "${count}" != "0" ]; then
              echo "‚úÖ Training task succeeded recently."
              break
            fi
            i=$((i+1))
            echo "‚Ä¶not done yet, sleeping ${SLEEP_SEC}s"
            sleep ${SLEEP_SEC}
          done
          if [ "${count}" = "0" ]; then
            echo "‚ùå Training task did not report success in time."
            exit 1
          fi

      # 6) Dump stage listing (debug)
      - name: List ONNX files in @ML_MODELS_STAGE (debug)
        run: |
          echo "üìú Stage listing:"
          snow sql -q "LIST @ML_MODELS_STAGE PATTERN='.*\\.onnx'" --format table || true

      # 7) Download the newest ONNX from stage (skip CSV header, strip stage prefix)
      - name: Download latest ONNX model from stage
        run: |
          echo "üì• Fetching latest ONNX model from @ML_MODELS_STAGE..."
          mkdir -p models
          # Get newest by last_modified (column 4), skip header
          raw_path=$(snow sql -q "LIST @ML_MODELS_STAGE PATTERN='.*\\.onnx'" --format csv \
            | tail -n +2 \
            | sort -t',' -k4,4r \
            | head -n1 \
            | cut -d',' -f1)
          if [ -z "$raw_path" ]; then
            echo "‚ùå No ONNX files found in @ML_MODELS_STAGE!"
            exit 1
          fi
          # Some Snowflake outputs include 'ml_models_stage/' prefix in the path ‚Äî strip if present
          file_rel="${raw_path#ml_models_stage/}"
          echo "‚úÖ Latest file (relative): $file_rel"
          snow sql -q "GET @ML_MODELS_STAGE/$file_rel file://./models/"
          echo "‚úÖ Model downloaded into ./models"

      # 8) Verify downloaded file(s)
      - name: Verify downloaded model
        run: |
          echo "üîé Verifying downloaded artifacts..."
          ls -lh models || true
          if ! ls models/*.onnx 1>/dev/null 2>&1; then
            echo "‚ùå No .onnx files were downloaded."
            exit 1
          fi
          echo "‚úÖ ONNX model present."

      # 9) Upload as GitHub artifact
      - name: Upload exported ONNX model
        uses: actions/upload-artifact@v4
        with:
          name: exported-onnx-model
          path: models/
          retention-days: 7

      # 10) Summary
      - name: Summary
        run: |
          echo "‚úÖ End-to-end pipeline completed."
          echo "‚úÖ Latest model trained by TASK_3 and fetched from @ML_MODELS_STAGE."


