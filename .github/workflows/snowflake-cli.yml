name: Snowflake Model Auto-Sync to GitHub

on:
  push:
    branches:
      - main

permissions:
  contents: write  # Required for pushing commits back to the repo

jobs:
  sync-snowflake-model:
    runs-on: ubuntu-latest
    name: Fetch and Commit Latest Model from Snowflake

    steps:
      # 1Ô∏è‚É£ Checkout repo
      - name: Checkout repository
        uses: actions/checkout@v4

      # 2Ô∏è‚É£ Install Snowflake CLI and jq
      - name: Install dependencies
        run: |
          echo "üß∞ Installing Snowflake CLI and jq..."
          pip install --upgrade snowflake-cli-labs
          sudo apt-get install -y jq
          snow --version

      # 3Ô∏è‚É£ Configure Snowflake connection
      - name: Configure Snowflake credentials
        env:
          SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
          SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}
          SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
          SNOWFLAKE_ROLE: ${{ secrets.SNOWFLAKE_ROLE }}
          SNOWFLAKE_WAREHOUSE: ${{ secrets.SNOWFLAKE_WAREHOUSE }}
          SNOWFLAKE_DATABASE: ${{ secrets.SNOWFLAKE_DATABASE }}
          SNOWFLAKE_SCHEMA: ${{ secrets.SNOWFLAKE_SCHEMA }}
        run: |
          mkdir -p ~/.snowflake
          cat <<EOF > ~/.snowflake/config.toml
          [connections.default]
          account = "${SNOWFLAKE_ACCOUNT}"
          user = "${SNOWFLAKE_USER}"
          password = "${SNOWFLAKE_PASSWORD}"
          role = "${SNOWFLAKE_ROLE}"
          warehouse = "${SNOWFLAKE_WAREHOUSE}"
          database = "${SNOWFLAKE_DATABASE}"
          schema = "${SNOWFLAKE_SCHEMA}"
          EOF
          chmod 600 ~/.snowflake/config.toml
          echo "‚úÖ Snowflake connection configured successfully."

      # 4Ô∏è‚É£ (Optional) Trigger training pipeline task
      - name: Trigger Snowflake training pipeline
        run: |
          echo "üöÄ Executing root Snowflake ML pipeline..."
          snow sql -q "
            USE WAREHOUSE MLOPS_WH;
            USE DATABASE POWERCONSUMPTION;
            USE SCHEMA PUBLIC;
            EXECUTE TASK TASK_1_DATA_INGESTION;
          "
          echo "‚úÖ Training pipeline triggered."

      # 5Ô∏è‚É£ Wait for training task success
      - name: Wait for TASK_3_MODEL_TRAINING success
        shell: bash
        run: |
          echo "‚è≥ Waiting for TASK_3_MODEL_TRAINING success..."
          ATTEMPTS=20
          SLEEP_SEC=30
          i=1
          while [ $i -le $ATTEMPTS ]; do
            count=$(snow sql --format csv -q "SELECT COUNT(*) FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY(SCHEDULED_TIME_RANGE_START => DATEADD('minute', -60, CURRENT_TIMESTAMP()))) WHERE NAME = 'TASK_3_MODEL_TRAINING' AND STATE = 'SUCCEEDED';" | tail -n +2 | cut -d',' -f1)
            echo "üîé success_count(last 60m) = ${count}"
            if [ "${count}" != "0" ]; then
              echo "‚úÖ Training task succeeded recently."
              break
            fi
            i=$((i+1))
            echo "‚Ä¶not done yet, sleeping ${SLEEP_SEC}s"
            sleep ${SLEEP_SEC}
          done
          if [ "${count}" = "0" ]; then
            echo "‚ùå Training task did not report success in time."
            exit 1
          fi

      # 6Ô∏è‚É£ List all ONNX models
      - name: List ONNX models in Snowflake stage
        run: |
          echo "üìú Listing ONNX models from stage..."
          snow sql -q "
            USE DATABASE POWERCONSUMPTION;
            USE SCHEMA PUBLIC;
            LIST @POWERCONSUMPTION.PUBLIC.ML_MODELS_STAGE PATTERN='.*\\.onnx';
          " --format table

      # 7Ô∏è‚É£ Download latest ONNX model and push to GitHub
      - name: Download latest ONNX file and push to repo
        run: |
          echo "üì• Fetching latest ONNX file from Snowflake stage..."
          mkdir -p staged_models

          # 1Ô∏è‚É£ Fetch and parse JSON output
          json_out=$(snow sql -q "
            USE DATABASE POWERCONSUMPTION;
            USE SCHEMA PUBLIC;
            LIST @POWERCONSUMPTION.PUBLIC.ML_MODELS_STAGE PATTERN='.*\\.onnx';
          " --format json)

          latest_file=$(echo "$json_out" | jq -r '
            flatten
            | map(select(.name? != null))
            | sort_by(.last_modified)
            | reverse
            | .[0].name
          ')

          if [ -z "$latest_file" ] || [ "$latest_file" == "null" ]; then
            echo "‚ùå No ONNX files found in stage!"
            echo "$json_out" | head -n 40
            exit 1
          fi

          echo "‚úÖ Latest file: $latest_file"

          # 2Ô∏è‚É£ Download it locally
          snow sql -q "GET @POWERCONSUMPTION.PUBLIC.ML_MODELS_STAGE/$latest_file file://staged_models/"
          echo "‚úÖ Model downloaded to staged_models/"

          # 3Ô∏è‚É£ Commit and push model to GitHub
          git config user.name "github-actions"
          git config user.email "actions@github.com"

          git add staged_models/
          git commit -m "Auto-sync ONNX model from Snowflake stage ($latest_file)" || echo "No new model changes"
          git push
          echo "‚úÖ Model file pushed successfully!"

      # 8Ô∏è‚É£ Summary
      - name: Summary
        run: |
          echo "‚úÖ End-to-end pipeline completed successfully!"
          echo "‚úÖ Latest ONNX model synced to GitHub under staged_models/ directory."
