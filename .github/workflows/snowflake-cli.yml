name: Snowflake End-to-End Model Pipeline (JSON Version - Auto Trigger)

on:
  push:
    branches:
      - main   # üîÅ Change this to your desired branch (e.g. "dev" or "*")

jobs:
  run-snowflake-cli:
    runs-on: ubuntu-latest
    name: Trigger Tasks ‚Üí Wait for Training ‚Üí Fetch Latest ONNX ‚Üí Upload

    steps:
      # 1Ô∏è‚É£ Checkout repository
      - name: Checkout repository
        uses: actions/checkout@v4

      # 2Ô∏è‚É£ Install Snowflake CLI and jq
      - name: Install Snowflake CLI
        run: |
          echo "üß∞ Installing Snowflake CLI and jq..."
          sudo apt-get update -y && sudo apt-get install -y jq
          pip install --upgrade snowflake-cli-labs
          snow --version
          jq --version

      # 3Ô∏è‚É£ Configure Snowflake credentials
      - name: Configure Snowflake credentials
        env:
          SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
          SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}
          SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
          SNOWFLAKE_ROLE: ${{ secrets.SNOWFLAKE_ROLE }}
          SNOWFLAKE_WAREHOUSE: ${{ secrets.SNOWFLAKE_WAREHOUSE }}
          SNOWFLAKE_DATABASE: ${{ secrets.SNOWFLAKE_DATABASE }}
          SNOWFLAKE_SCHEMA: ${{ secrets.SNOWFLAKE_SCHEMA }}
        run: |
          mkdir -p ~/.snowflake
          cat <<EOF > ~/.snowflake/config.toml
          [connections.default]
          account = "${SNOWFLAKE_ACCOUNT}"
          user = "${SNOWFLAKE_USER}"
          password = "${SNOWFLAKE_PASSWORD}"
          role = "${SNOWFLAKE_ROLE}"
          warehouse = "${SNOWFLAKE_WAREHOUSE}"
          database = "${SNOWFLAKE_DATABASE}"
          schema = "${SNOWFLAKE_SCHEMA}"
          EOF
          chmod 600 ~/.snowflake/config.toml
          echo "‚úÖ Snowflake credentials configured."

      # 4Ô∏è‚É£ Trigger the root task so the entire chain (1‚Üí2‚Üí3‚Üí4) runs
      - name: Trigger Snowflake ML pipeline (root task)
        run: |
          echo "üöÄ Executing pipeline (root task)..."
          snow sql -q "
            USE WAREHOUSE MLOPS_WH;
            USE DATABASE POWERCONSUMPTION;
            USE SCHEMA PUBLIC;
            EXECUTE TASK TASK_1_DATA_INGESTION;
          "
          echo "‚úÖ Root task executed."

      # 5Ô∏è‚É£ Poll until TASK_3_MODEL_TRAINING succeeded recently
      - name: Wait for TASK_3_MODEL_TRAINING to succeed
        run: |
          echo "‚è≥ Waiting for TASK_3_MODEL_TRAINING success..."
          ATTEMPTS=20
          SLEEP_SEC=30
          i=1
          while [ $i -le $ATTEMPTS ]; do
            count=$(snow sql -q "
              SELECT COUNT(*) AS C
              FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY(
                SCHEDULED_TIME_RANGE_START => DATEADD('minute', -45, CURRENT_TIMESTAMP())
              ))
              WHERE name = 'TASK_3_MODEL_TRAINING'
                AND state = 'SUCCEEDED';
            " --format json | jq -r '(try .data catch .) | .[0].C // 0')
            echo "üîé success_count(last 45m) = ${count}"
            if [ "${count}" != "0" ]; then
              echo "‚úÖ Training task succeeded recently."
              break
            fi
            i=$((i+1))
            echo "‚Ä¶not done yet, sleeping ${SLEEP_SEC}s"
            sleep ${SLEEP_SEC}
          done
          if [ "${count}" = "0" ]; then
            echo "‚ùå Training task did not report success in time."
            exit 1
          fi

      # 6Ô∏è‚É£ Debug listing
      - name: List ONNX files in @ML_MODELS_STAGE (debug)
        run: |
          echo "üìú Stage listing (JSON):"
          snow sql -q "LIST @ML_MODELS_STAGE PATTERN='.*\\.onnx'" --format json | jq '.data'

      # 7Ô∏è‚É£ Download newest ONNX using JSON parsing
      - name: Download latest ONNX model from stage (JSON)
        run: |
          echo "üì• Fetching latest ONNX model from @ML_MODELS_STAGE..."
          mkdir -p models
          latest_file=$(snow sql -q "LIST @ML_MODELS_STAGE PATTERN='.*\\.onnx'" --format json \
            | jq -r '[.data[] | {name: .name, last_modified: .last_modified}] 
                     | sort_by(.last_modified) 
                     | last 
                     | .name')
          if [ -z "$latest_file" ] || [ "$latest_file" = "null" ]; then
            echo "‚ùå No ONNX file found in @ML_MODELS_STAGE!"
            exit 1
          fi
          file_rel="${latest_file#ml_models_stage/}"
          echo "‚úÖ Latest ONNX file: $file_rel"
          snow sql -q "GET @ML_MODELS_STAGE/$file_rel file://./models/"
          echo "‚úÖ Model downloaded to ./models"

      # 8Ô∏è‚É£ Verify file(s)
      - name: Verify downloaded model
        run: |
          echo "üîé Verifying downloaded ONNX..."
          ls -lh models || true
          if ! ls models/*.onnx 1>/dev/null 2>&1; then
            echo "‚ùå No .onnx files were downloaded."
            exit 1
          fi
          echo "‚úÖ ONNX model present."

      # 9Ô∏è‚É£ Upload artifact
      - name: Upload exported ONNX model
        uses: actions/upload-artifact@v4
        with:
          name: exported-onnx-model
          path: models/
          retention-days: 7

      # üîü Summary
      - name: Summary
        run: |
          echo "‚úÖ End-to-end pipeline completed."
          echo "‚úÖ Latest model trained by TASK_3 and fetched (JSON-based) from @ML_MODELS_STAGE."




